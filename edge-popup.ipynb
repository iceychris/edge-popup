{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge-Popup\n",
    "\n",
    "Paper: [https://arxiv.org/abs/1911.13299](https://arxiv.org/abs/1911.13299)\n",
    "\n",
    "Code adapted from: [train_imagenette.py](https://github.com/fastai/fastai2/blob/master/nbs/examples/train_imagenette.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastai2.basics import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.distributed import *\n",
    "from fastprogress import fastprogress\n",
    "from torchvision.models import *\n",
    "from fastai2.vision.models.xresnet import *\n",
    "from fastai2.callback.mixup import *\n",
    "from fastscript import *\n",
    "\n",
    "from lib.layers import Conv2dSubnet, LinearSubnet\n",
    "from lib.utils import adapt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbunch(size, woof, bs, sh=0., workers=None):\n",
    "    if size<=224: path = URLs.IMAGEWOOF_320 if woof else URLs.IMAGENETTE_320\n",
    "    else        : path = URLs.IMAGEWOOF     if woof else URLs.IMAGENETTE\n",
    "    source = untar_data(path)\n",
    "    if workers is None: workers = min(8, num_cpus())\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                       splitter=GrandparentSplitter(valid_name='val'),\n",
    "                       get_items=get_image_files, get_y=parent_label)\n",
    "    item_tfms=[RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)]\n",
    "    batch_tfms=RandomErasing(p=0.3, max_count=3, sh=sh) if sh else None\n",
    "    return dblock.databunch(source, path=source, bs=bs, num_workers=workers,\n",
    "                            item_tfms=item_tfms, batch_tfms=batch_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    gpu:   Param(\"GPU to run on\", int)=None,\n",
    "    woof:  Param(\"Use imagewoof (otherwise imagenette)\", int)=0,\n",
    "    lr:    Param(\"Learning rate\", float)=1e-2,\n",
    "    size:  Param(\"Size (px: 128,192,256)\", int)=128,\n",
    "    sqrmom:Param(\"sqr_mom\", float)=0.99,\n",
    "    mom:   Param(\"Momentum\", float)=0.9,\n",
    "    eps:   Param(\"epsilon\", float)=1e-6,\n",
    "    epochs:Param(\"Number of epochs\", int)=20,\n",
    "    bs:    Param(\"Batch size\", int)=64,\n",
    "    mixup: Param(\"Mixup\", float)=0.,\n",
    "    opt:   Param(\"Optimizer (adam,rms,sgd,ranger)\", str)='ranger',\n",
    "    arch:  Param(\"Architecture\", str)='xresnet50',\n",
    "    sh:    Param(\"Random erase max proportion\", float)=0.,\n",
    "    sa:    Param(\"Self-attention\", int)=0,\n",
    "    sym:   Param(\"Symmetry for self-attention\", int)=0,\n",
    "    beta:  Param(\"SAdam softplus beta\", float)=0.,\n",
    "    act_fn:Param(\"Activation function\", str)='MishJit',\n",
    "    fp16:  Param(\"Use mixed precision training\", int)=0,\n",
    "    pool:  Param(\"Pooling method\", str)='AvgPool',\n",
    "    dump:  Param(\"Print model; don't train\", int)=0,\n",
    "    runs:  Param(\"Number of times to repeat training\", int)=1,\n",
    "    sub:   Param(\"Use edge-popup subnets\", bool)=True,\n",
    "    meta:  Param(\"Metadata (ignored)\", str)=''\n",
    "):\n",
    "    \"Training of Imagenette.\"\n",
    "\n",
    "    #gpu = setup_distrib(gpu)\n",
    "    if gpu is not None: torch.cuda.set_device(gpu)\n",
    "    if   opt=='adam'  : opt_func = partial(Adam, mom=mom, sqr_mom=sqrmom, eps=eps)\n",
    "    elif opt=='rms'   : opt_func = partial(RMSprop, sqr_mom=sqrmom)\n",
    "    elif opt=='sgd'   : opt_func = partial(SGD, mom=mom)\n",
    "    elif opt=='ranger': opt_func = partial(ranger, mom=mom, sqr_mom=sqrmom, eps=eps, beta=beta)\n",
    "\n",
    "    dbunch = get_dbunch(size, woof, bs, sh=sh)\n",
    "    if not gpu: print(f'epochs: {epochs}; lr: {lr}; size: {size}; sqrmom: {sqrmom}; mom: {mom}; eps: {eps}')\n",
    "\n",
    "    mk_m,act_fn,pool = [globals()[o] for o in (arch,act_fn,pool)]\n",
    "\n",
    "    for run in range(runs):\n",
    "        print(f'Run: {run}')\n",
    "        \n",
    "        # create and adapt model\n",
    "        m = mk_m(c_out=10, act_cls=act_fn, sa=sa, sym=sym, pool=pool)\n",
    "        if sub:\n",
    "            adapt_model(m, orig=nn.Conv2d, new=Conv2dSubnet)\n",
    "        \n",
    "        learn = Learner(dbunch, m, opt_func=opt_func, \\\n",
    "                metrics=[accuracy,top_k_accuracy], loss_func=LabelSmoothingCrossEntropy())\n",
    "        if dump: print(learn.model); exit()\n",
    "        if fp16: learn = learn.to_fp16()\n",
    "        cbs = MixUp(mixup) if mixup else []\n",
    "        #n_gpu = torch.cuda.device_count()\n",
    "        #if gpu is None and n_gpu: learn.to_parallel()\n",
    "        if num_distrib()>1: learn.to_distributed(gpu) # Requires `-m fastai.launch`\n",
    "        learn.fit_flat_cos(epochs, lr, wd=1e-2, cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(sub=False, epochs=20, arch=\"xresnet50\", runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
